-This code does the same thing with previous code which is in the README file but this one uses neural network instead of the previous methods.
-If the output is bigger than 0.5, program predicts that it is a fraud. If it is smaller than 0.5, program predicts that it is not a fraud.
-Data source is the same with the previous one which is from Kaggle.
'''
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2, f_classif
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import SCORERS, confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.naive_bayes import BernoulliNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# Load data from CSV
df = pd.read_csv('card_transdata.csv')

# Split into features and target
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data to zero mean and unit variance
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build neural network model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile model with binary crossentropy loss function and Adam optimizer
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train model on training data
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate model on testing data
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

emily = np.array([[21.12611616077098,0.27198739643980063,6.081770719263626,1.0,0.0,0.0,1.0]]) 
frank = np.array([[15.23536145541202,0.30020872455242303,0.4642727680509552,1.0,0.0,0.0,0.0]])
p1=model.predict(emily) 
p2=model.predict(frank)
print("Emily:",p1)
print("Frank:",p2)
'''
